{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des libraries\n",
    "\n",
    "from bigml.api import BigML\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions\n",
    "\n",
    "def threshold(row):\n",
    "    if row['1 probability'] < threshold_value:\n",
    "        prediction_value = 0\n",
    "    else: \n",
    "        prediction_value = 1\n",
    "    return prediction_value\n",
    "\n",
    "def error_column(row):\n",
    "    if(row['SeriousDlqin2yrs'] == 0 and row['prediction'] == 0):\n",
    "        error_value = 'TN'\n",
    "    if(row['SeriousDlqin2yrs'] == 1 and row['prediction'] == 0):\n",
    "        error_value = 'FN'\n",
    "    if(row['SeriousDlqin2yrs'] == 0 and row['prediction'] == 1):\n",
    "        error_value = 'FP'\n",
    "    if(row['SeriousDlqin2yrs'] == 1 and row['prediction'] == 1):\n",
    "        error_value = 'TP'\n",
    "    return error_value\n",
    "\n",
    "def confusion_matrix():\n",
    "    idx = pandas.Index(df['error'])\n",
    "    count_matrix = idx.value_counts() \n",
    "    return count_matrix\n",
    "\n",
    "def get_accuracy():\n",
    "    matrix = list(df.error.values)\n",
    "    tn = matrix.count('TN')\n",
    "    fn = matrix.count('FN')\n",
    "    tp = matrix.count('TP')\n",
    "    fp = matrix.count('FP')\n",
    "    total = tn + fn + tp + fp\n",
    "    accuracy = ((tp + tn ) / total ) * 100\n",
    "    return accuracy\n",
    "\n",
    "def get_profits():\n",
    "    matrix = list(df.error.values)\n",
    "    val_tn = 500\n",
    "    val_fn = -2500\n",
    "    val_tp = 0\n",
    "    val_fp = -500\n",
    "    profits = matrix.count('TN') * val_tn + matrix.count('FN') * val_fn + matrix.count('TP') * val_tp + matrix.count('FP') * val_fp\n",
    "    return profits\n",
    "\n",
    "# On cherche parmis les FN ( Prediction = 0 , Réalité  = 1 ) les plus petites 1 Proba ( Le modele prédisait quasi certainement 0)\n",
    "def biggest_mistakes():\n",
    "    filtered = df.loc[df['error'].isin([\"FN\"])]\n",
    "    filtered = (filtered.nsmallest(100, '1 probability'))\n",
    "    filtered.to_csv(\"100_biggest_mistakes.csv\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du seuil\n",
    "\n",
    "threshold_value = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la feuille csv & applications des modifications\n",
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('Prediction2.csv', index_col=0)\n",
    "df.rename(columns={\"SeriousDlqin2yrs.1\": \"prediction\"}, inplace= True)\n",
    "df['prediction'] = df.apply(threshold, axis = 1)\n",
    "df['error'] = df.apply(error_column, axis = 1)\n",
    "print(\"Load & Modifications : OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "\n",
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profits\n",
    "\n",
    "get_profits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 plus grosses erreurs de notre modèle ( Parmis les FN , + petites 1 proba)\n",
    "\n",
    "biggest_mistakes()\n",
    "print(\"Enregistrement du fichier .csv en local :  OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction(threshold) = profits\n",
    "\n",
    "def cost_threshold(threshold):\n",
    "    # Return True si 1 Proba > seuil & False si 1 Proba < seuil\n",
    "    prediction_threshold = df['1 probability'] > threshold\n",
    "    \n",
    "    P_pred = prediction_threshold # Renvoie True si 1 proba > seuil ( sinon False )\n",
    "    N_pred = ~prediction_threshold # Renvoie True si 1 proba < seuil ( sinon False )\n",
    "    \n",
    "    P_real = (df['SeriousDlqin2yrs'] == 1) # Renvoie True si SeriousDlqin2Yrs == 1 ( sinon False )\n",
    "    N_real = (df['SeriousDlqin2yrs'] == 0) # Renvoie True si SeriousDlqin2Yrs == 0 ( sinon False )\n",
    "    \n",
    "    # P_pred True si 1 proba > seuil Prediction =  1 , P_real True si Realite = 1 \n",
    "    TP = len(df.loc[P_pred & P_real])\n",
    "    # N_pred True = si 1 proba < seuil = Prediction = 0 , N_real True si Realité 0 \n",
    "    TN = len(df.loc[N_pred & N_real])\n",
    "    # P_pred True si 1 proba > seuil Prediction = 1 , N_real True si Réalite = 0\n",
    "    FP = len(df.loc[P_pred & N_real])\n",
    "    # N_pred True si 1 proba < seuil =  Prediction 0 , P_real True si Realité = 1\n",
    "    FN = len(df.loc[N_pred & P_real])\n",
    "    \n",
    "    TP_cost = 0\n",
    "    FN_cost = -2500\n",
    "    FP_cost = -500\n",
    "    TN_cost = 500\n",
    "    \n",
    "    cost = TP * TP_cost\n",
    "    cost += TN * TN_cost\n",
    "    cost += FP * FP_cost\n",
    "    cost += FN * FN_cost\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique et affichage du seuil opti\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# on fait varier le seuil de 0 à 1000 / 1000 => 0.0001 , 0.0002 ... 1 dans la fonction seuil => gain\n",
    "table = [cost_threshold(n/1000) for n in range(0,1000)]\n",
    "plt.xlabel(\"seuil/1000\")\n",
    "plt.ylabel(\"Gains\")\n",
    "plt.title(\"GiveMeCredit - Kaggle\")\n",
    "\n",
    "plt.plot(table)\n",
    "\n",
    "max_val = max(table)\n",
    "max_threshold = table.index(max_val)/1000\n",
    "print(f'gain max {max_val} $ | Seuil {max_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de l'AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode Laurent\n",
    "\n",
    "# Tri des données pour préparer le calcul de AUC\n",
    "\n",
    "df = read_csv('Prediction2.csv', index_col=0)\n",
    "df_sorted = df.sort_values('1 probability', ascending=False)\n",
    "df\n",
    "\n",
    "#  Calcul de la somme des négatifs en dessous de chaque positifs (1 probability est inférieur)\n",
    "\n",
    "N_sum_below = 0\n",
    "for index in range(len(df_sorted)):\n",
    "    if df_sorted['SeriousDlqin2yrs'].iloc[index] == 1:\n",
    "        N_sum_below += df_sorted['SeriousDlqin2yrs'][index+1:].value_counts().loc[0]\n",
    "\n",
    "print(N_sum_below)\n",
    "\n",
    "# Calcul du produit nombre N * nombre P\n",
    "N_number = df_sorted['SeriousDlqin2yrs'].value_counts().loc[0]\n",
    "P_number  = df_sorted['SeriousDlqin2yrs'].value_counts().loc[1]\n",
    "NP_product = N_number * P_number\n",
    "\n",
    "# Calcul auc\n",
    "AUC = N_sum_below / NP_product\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode Maud\n",
    "\n",
    "df = read_csv('Prediction2.csv', index_col=0)\n",
    "\n",
    "positive = (df['SeriousDlqin2yrs'] == 1)\n",
    "nb_positive=len(df.loc[positive])\n",
    "nb_negative=len(df.loc[~positive])\n",
    "\n",
    "result = df[['SeriousDlqin2yrs','1 probability']]\n",
    "threshold_list = result.sort_values(by='1 probability',ascending=False)['SeriousDlqin2yrs'].values\n",
    "\n",
    "\n",
    "auc = 0\n",
    "P_cumul = 0\n",
    "\n",
    "for i in range(len(threshold_list)):\n",
    "    if threshold_list[i] == 1:\n",
    "        P_cumul += 1\n",
    "    else:\n",
    "        auc += P_cumul\n",
    "        \n",
    "auc = auc/(nb_positive*nb_negative)\n",
    "\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # affichage des 100 plus grandes erreurs du modele\n",
    "\n",
    "# filtered = df.loc[df['Classification'].isin([\"FN\"])]\n",
    "# filtered = (filtered.nsmallest(100, 'My Prediction'))\n",
    "# # filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Calcul du nombre de FP/FN/VP/VN\n",
    "\n",
    "# df = read_csv('Prediction_with_error.csv', index_col=0)\n",
    "# df.loc[(df[\"SeriousDlqin2yrs\"] == 0) & (df[\"My Prediction\"] == 0), 'Classification'] = 'TN'\n",
    "# df.loc[(df[\"SeriousDlqin2yrs\"] == 0) & (df[\"My Prediction\"] == 1), 'Classification'] = 'FP'\n",
    "# df.loc[(df[\"SeriousDlqin2yrs\"] == 1) & (df[\"My Prediction\"] == 0), 'Classification'] = 'FN'\n",
    "# df.loc[(df[\"SeriousDlqin2yrs\"] == 1) & (df[\"My Prediction\"] == 1), 'Classification'] = 'TP'\n",
    "\n",
    "# idx = pandas.Index(df['Classification'])\n",
    "# idx.value_counts()\n",
    "# count_matrix = idx.value_counts()\n",
    "\n",
    "# accuracy = (count_matrix[0] + count_matrix[2]) / ( count_matrix[0] + count_matrix[1] + count_matrix[2] + count_matrix[3]) * 100\n",
    "# print(accuracy)\n",
    "# df\n",
    "\n",
    "# gains = count_matrix[0] * 500 + count_matrix[1] * -2500 + count_matrix[2] * 0 + count_matrix[3] * -500\n",
    "# print(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Insertion colonne d'erreur avec seuil defini\n",
    "\n",
    "# df = read_csv('Prediction.csv', index_col=0)\n",
    "# df.rename(columns={\"1 probability\": \"Probability1\"}, inplace= True)\n",
    "# df.rename(columns={\"0 probability\": \"Probability0\"}, inplace= True)\n",
    "# df.loc[df.Probability1 > 0.25 , 'My Prediction'] = '1'\n",
    "# df.loc[df.Probability1 < 0.25 , 'My Prediction'] = '0'\n",
    "# df.to_csv('Prediction_with_error.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
